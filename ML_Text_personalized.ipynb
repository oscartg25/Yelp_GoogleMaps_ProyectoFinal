{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJo69XyqiutI9M5zYv+kns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscartg25/Yelp_GoogleMaps_ProyectoFinal/blob/master/ML_Text_personalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "DHdLc6gvGwHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyixsUne4z7R",
        "outputId": "b0de5d46-506a-45e7-bb91-ae93704467af"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "D6b5wfZRFvax"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai  # Importamos la biblioteca OpenAI\n",
        "import spacy\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cargamos la data\n",
        "df_rating = pd.read_csv('text_rating.csv')"
      ],
      "metadata": {
        "id": "_cHLNB29Gb-7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar tu API Key de GooseAI\n",
        "openai.api_key = \"sk-AcM7DAh7ELJ7gTbE02KvlmKBJ5gXCIdH3nJ40G62sSwc1A3S\"\n",
        "\n",
        "openai.api_base = \"https://api.goose.ai/v1\""
      ],
      "metadata": {
        "id": "DrN5e-b5diZL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la lista de motores disponibles\n",
        "engines = openai.Engine.list()"
      ],
      "metadata": {
        "id": "s4RS44aExphs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir información sobre cada motor\n",
        "for engine in engines.data:\n",
        "    print(\"Engine ID:\", engine.id)\n",
        "    print(\"Engine Name:\", engine.name)\n",
        "    print(\"Engine Description:\", engine.description)\n",
        "    print(\"Tokenizer:\", engine.tokenizer)\n",
        "    print(\"Ready:\", engine.ready)\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2PSuO0xzxN",
        "outputId": "d2837c9a-6e55-4039-9444-d3ec0f3e6f67"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engine ID: cassandra-lit-2-8b\n",
            "Engine Name: Cassandra 2.8B\n",
            "Engine Description: A literary finetune based on the Pythia 2.8b model with about 400mb of texts from various science fiction, fantasy, fiction, horror, and interactive fiction. Great at chat!\n",
            "Tokenizer: pile\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: cassandra-lit-6-9b\n",
            "Engine Name: Cassandra 6.9B\n",
            "Engine Description: A literary finetune based on the Pythia 2.8b model with about 400mb of texts from various science fiction, fantasy, fiction, horror, and interactive fiction. Great at chat!\n",
            "Tokenizer: pile\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: convo-6b\n",
            "Engine Name: Convo 6B\n",
            "Engine Description: Convo-6B is a GPT-J 6B model fine-tuned on a collection of high quality open source datasets which amount to 6 million messages. The primary goal of the model is to provide improved performance and generalization when generating multi-turn dialogue for characters that were not present from within the fine tuning data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: fairseq-125m\n",
            "Engine Name: Fairseq 125M\n",
            "Engine Description: 125M parameter Facebook Mixture of Experts model trained on RoBERTa and CC100 subset data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: fairseq-355m\n",
            "Engine Name: Fairseq 355M\n",
            "Engine Description: 355M parameter Facebook Mixture of Experts model trained on RoBERTa and CC100 subset data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: fairseq-1-3b\n",
            "Engine Name: Fairseq 1.3B\n",
            "Engine Description: 1.3B parameter Facebook Mixture of Experts model trained on RoBERTa and CC100 subset data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: fairseq-2-7b\n",
            "Engine Name: Fairseq 2.7B\n",
            "Engine Description: 2.7B parameter Facebook Mixture of Experts model trained on RoBERTa and CC100 subset data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: fairseq-6-7b\n",
            "Engine Name: Fairseq 6.7B\n",
            "Engine Description: 6.7B parameter Facebook Mixture of Experts model trained on RoBERTa and CC100 subset data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: fairseq-13b\n",
            "Engine Name: Fairseq 13B\n",
            "Engine Description: 13B parameter Facebook Mixture of Experts model trained on RoBERTa and CC100 subset data.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: gpt-j-6b\n",
            "Engine Name: GPT-J 6B\n",
            "Engine Description: 6B parameter EleutherAI model trained on the Pile, using the Mesh Transformer JAX framework.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: gpt-neo-125m\n",
            "Engine Name: GPT-Neo 125M\n",
            "Engine Description: 125M parameter EleutherAI model trained on the Pile, using the Neo framework.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: gpt-neo-1-3b\n",
            "Engine Name: GPT-Neo 1.3B\n",
            "Engine Description: 1.3B parameter EleutherAI model trained on the Pile, using the Neo framework.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: gpt-neo-2-7b\n",
            "Engine Name: GPT-Neo 2.7B\n",
            "Engine Description: 2.7B parameter EleutherAI model trained on the Pile, using the Neo framework.\n",
            "Tokenizer: gpt2\n",
            "Ready: True\n",
            "---\n",
            "Engine ID: gpt-neo-20b\n",
            "Engine Name: GPT-NeoX 20B\n",
            "Engine Description: 20B parameter EleutherAI model trained on the Pile, using the NeoX framework.\n",
            "Tokenizer: pile\n",
            "Ready: True\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleccionamos Motor\n",
        "selected_engine_id = \"gpt-neo-1-3b\""
      ],
      "metadata": {
        "id": "3gKSnTfpx343"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para generar respuesta usando Goose.ai\n",
        "def generate_response(comment):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-neo-1-3b\",  # Reemplaza con el ID del motor que deseas utilizar\n",
        "        prompt=comment,\n",
        "        max_tokens=50  # Ajustar este valor según tus necesidades\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n"
      ],
      "metadata": {
        "id": "FAK00xlEdrWt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para analizar el sentimiento\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment = blob.sentiment.polarity\n",
        "    if sentiment > 0:\n",
        "        return 5\n",
        "    elif sentiment == 0:\n",
        "        return 3\n",
        "    else:\n",
        "        return 1\n"
      ],
      "metadata": {
        "id": "ZCeWJo-Fdyxq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterar a través de los comentarios en el DataFrame\n",
        "for index, row in df_rating.iterrows():\n",
        "    comment = row['text']\n",
        "\n",
        "    if isinstance(comment, str):  # Solo procesar comentarios no nulos\n",
        "        generated_response = generate_response(comment)\n",
        "        sentiment_label = analyze_sentiment(comment)\n",
        "\n",
        "        df_rating.at[index, 'generated_response'] = generated_response\n",
        "        df_rating.at[index, 'predicted_rating'] = sentiment_label"
      ],
      "metadata": {
        "id": "3FzTMxKyd9sP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar el DataFrame con las respuestas generadas y las predicciones de rating\n",
        "print(df_rating)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9E7a7MMJHII",
        "outputId": "45e007f6-7ad6-474b-8a65-8844fdc90326"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  text  rating  \\\n",
            "0    The lunch buffet was really good! Would defini...     NaN   \n",
            "1                                   Sweet potato fries     NaN   \n",
            "2    Ciders please! None on tap right now but next ...     NaN   \n",
            "3    This has quickly become my new favorite restau...     NaN   \n",
            "4                                          Madness....     NaN   \n",
            "..                                                 ...     ...   \n",
            "495                              Sit in the courtyard!     NaN   \n",
            "496  Amazing ambience in a historic hotel.  Creativ...     NaN   \n",
            "497  This is a great place to bring your little one...     NaN   \n",
            "498  I loved my vegan pizza w/ teese!! Absolutely a...     NaN   \n",
            "499                                  Yelp elite event!     NaN   \n",
            "\n",
            "                                    generated_response sentiment_label  \\\n",
            "0    if the chance came up. Who knows I might claim...        positivo   \n",
            "1    . Caramelized onions and butter served with gr...        positivo   \n",
            "2    Think about getting the sake but it runs a bit...        positivo   \n",
            "3    0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0\\n\\n0...        positivo   \n",
            "4    I only don't mind reality.\"\\n\\n\"But do you lik...         neutral   \n",
            "..                                                 ...             ...   \n",
            "495  string a pin to the crown of the flush\\ncontin...         neutral   \n",
            "496  ADD  BED 341\\n\\nNEW JUNE \\n\\nHOTEL  BXB ST434\\...        positivo   \n",
            "497  -----Original Message-----\\nFrom: \\tMims, Patr...        positivo   \n",
            "498  Refined! I later made low-fat vegetarian and v...        positivo   \n",
            "499  April 9, 2018 / 2:00 pm\\n\\nOnly \"only players\"...         neutral   \n",
            "\n",
            "     predicted_rating  \n",
            "0                 5.0  \n",
            "1                 5.0  \n",
            "2                 5.0  \n",
            "3                 5.0  \n",
            "4                 3.0  \n",
            "..                ...  \n",
            "495               3.0  \n",
            "496               5.0  \n",
            "497               5.0  \n",
            "498               5.0  \n",
            "499               3.0  \n",
            "\n",
            "[500 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingresar un texto personalizado para obtener el rating predicho\n",
        "custom_text = \"This restaurant is shit\"\n",
        "custom_sentiment_label = analyze_sentiment(custom_text)\n",
        "custom_predicted_rating = custom_sentiment_label\n",
        "print(\"Texto personalizado:\", custom_text)\n",
        "print(\"Análisis de sentimiento:\", custom_sentiment_label)\n",
        "print(\"Rating predicho:\", custom_predicted_rating)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_f5yaIiMh-P",
        "outputId": "54232707-4b70-4fc2-a3ba-2ba2f3db38b9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto personalizado: This restaurant is shit\n",
            "Análisis de sentimiento: 1\n",
            "Rating predicho: 1\n"
          ]
        }
      ]
    }
  ]
}